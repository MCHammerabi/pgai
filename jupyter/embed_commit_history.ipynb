{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import psycopg2.extras as extras \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import os\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "conn = pg.connect(os.getenv('AI_DB_URL'))\n",
    "open_ai_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# commit history column headers\n",
    "col_headers = ['id', 'author', 'commit_time', 'commit_id', 'commit_title', 'commit_comments']\n",
    "\n",
    "# tiktoken encoding: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "tt_encoding = 'cl100k_base'\n",
    "\n",
    "# Assumes we're using the text-embedding-ada-002 model\n",
    "# See https://openai.com/pricin\n",
    "embed_cost = 0.0000001 # $0.10 per 1M  <check current pricing!>\n",
    "\n",
    "# choose from dictionary models directly below\n",
    "model_num = 26 \n",
    "\n",
    "# from running config_openai.ipynb\n",
    "models = {  0: 'gpt-4o-2024-05-13', 1: 'gpt-4o', 2: 'gpt-4-turbo-2024-04-09', 3: 'gpt-4-turbo', 4: 'gpt-3.5-turbo-0125',\n",
    "            5: 'gpt-4-turbo-preview', 6: 'gpt-4-0125-preview', 7: 'text-embedding-3-large', 8: 'text-embedding-3-small',\n",
    "            9: 'tts-1-hd-1106', 10: 'tts-1-1106', 11: 'tts-1-hd', 12: 'gpt-3.5-turbo-1106', 13: 'gpt-4-1106-preview',\n",
    "            14: 'dall-e-2', 15: 'dall-e-3', 16: 'gpt-3.5-turbo-instruct-0914', 17: 'gpt-3.5-turbo-instruct',\n",
    "            18: 'babbage-002', 19: 'davinci-002', 20: 'gpt-4', 21: 'gpt-4-0613', 22: 'gpt-3.5-turbo-16k',\n",
    "            23: 'tts-1', 24: 'gpt-3.5-turbo', 25: 'whisper-1', 26: 'text-embedding-ada-002'  }\n",
    "\n",
    "# Helper func: calculate number of tokens\n",
    "def num_tokens_from_string(string, encoding_name):\n",
    "    try:\n",
    "        if not string:\n",
    "            return False # maybe raise exception instead :)\n",
    "        # Returns the number of tokens in a text string\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        num_tokens = len(encoding.encode(string))\n",
    "        return num_tokens\n",
    "    except Exception as e:\n",
    "            print('Error in num_tokens_from_string: {}'.format(e))   \n",
    "\n",
    "# Helper function: calculate cost of embedding num_tokens        \n",
    "def get_embedding_cost(num_tokens, token_cost):\n",
    "    try:\n",
    "        return num_tokens * token_cost\n",
    "    except Exception as e:\n",
    "        print('Error in num_tokens_from_string: {}'.format(e))      \n",
    "\n",
    "class Openai:\n",
    "    def __init__(self):\n",
    "        self.ch_columns = col_headers\n",
    "        self.encoding = tt_encoding\n",
    "        self.embed_cost = embed_cost\n",
    "        self.embed_model = models[model_num]\n",
    "        \n",
    "    def get_params(self):\n",
    "        return {\n",
    "            'ch_cols': self.ch_columns,\n",
    "            'encoding': self.encoding,\n",
    "            'token_cost': self.embed_cost,\n",
    "            'model': self.embed_model\n",
    "        }\n",
    "    \n",
    "    def get_notices(self):\n",
    "        for notice in conn.notices:\n",
    "            print('')\n",
    "            print('***Message from Postgres: {}'.format(notice))\n",
    "        return True\n",
    "    \n",
    "    def get_total_embeddings_cost(self, old_df, encode, cost):\n",
    "        try:\n",
    "            df = old_df.copy(deep=True)\n",
    "            df['content'] = df['author'] + df['commit_time'] + df['commit_id'] + df['commit_title'] + df['commit_comments']\n",
    "            total_tokens = 0\n",
    "            for i in range(len(df.index)):\n",
    "                text = df['content'][i]\n",
    "                token_len = num_tokens_from_string(text, encode)\n",
    "                total_tokens = total_tokens + token_len\n",
    "            total_cost = get_embedding_cost(total_tokens, cost)\n",
    "            return total_cost\n",
    "        except Exception as e:\n",
    "            print('Error in get_total_embeddings_cost: {}'.format(e)) \n",
    "\n",
    "def create_commit_hist_table(pg_notice):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        sql = '''\n",
    "            DROP TABLE IF EXISTS commit_history;\n",
    "        \n",
    "            CREATE TABLE commit_history (\n",
    "                id BIGINT PRIMARY KEY,\n",
    "                author TEXT NOT NULL,\n",
    "                commit_time TIMESTAMPTZ NOT NULL,\n",
    "                commit_id TEXT NOT NULL,\n",
    "                commit_title TEXT NOT NULL,\n",
    "                commit_comments TEXT     \n",
    "            );\n",
    "        '''\n",
    "        cur.execute(sql)\n",
    "        cur.close()\n",
    "        conn.commit()\n",
    "        pg_notice()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('Error in create_commit_hist_table: {}'.format(e)) \n",
    "        \n",
    "def read_commit_hist(cols):\n",
    "    try:\n",
    "        df = pd.read_csv('data/input/commit_history.csv', names=cols)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print('Error in read_commit_hist: {}'.format(e))\n",
    "        \n",
    "def write_commit_hist(df, pg_notice):\n",
    "    try:\n",
    "        table = 'commit_history'\n",
    "        tuples = [tuple(rec) for rec in df.to_numpy()]\n",
    "        cols = ','.join(list(df.columns)) \n",
    "        # SQL query to execute \n",
    "        query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols) \n",
    "        cur = conn.cursor() \n",
    "        try: \n",
    "            extras.execute_values(cur, query, tuples) \n",
    "            pg_notice()\n",
    "            conn.commit() \n",
    "        except (Exception, pg.DatabaseError) as error: \n",
    "            print(\"Error: %s\" % error) \n",
    "            conn.rollback() \n",
    "            cur.close() \n",
    "            return False\n",
    "        print(\"the dataframe is inserted\") \n",
    "        cur.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('Error in read_commit_hist: {}'.format(e))\n",
    "\n",
    "def fetch_ch_ids():\n",
    "    cur = conn.cursor()\n",
    "    query = '''\n",
    "        SELECT array_to_json(array_agg(id)) from\n",
    "            (SELECT id FROM commit_history) sq\n",
    "    '''\n",
    "    cur.execute(query)\n",
    "    return cur.fetchall()[0][0]\n",
    "\n",
    "def create_vector_table(pg_notice):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        sql = '''\n",
    "            DROP TABLE IF EXISTS commit_history_vector;\n",
    "        \n",
    "            CREATE TABLE commit_history_vector (\n",
    "                id BIGINT PRIMARY KEY,\n",
    "                embedding vector(1536) -- the vector type comes from the pgvector extension\n",
    "            );\n",
    "        '''\n",
    "        cur.execute(sql)\n",
    "        conn.commit()\n",
    "        pg_notice()\n",
    "    except Exception as e:\n",
    "        print('Error in create_vector_table: {}'.format(e))    \n",
    "\n",
    "def ch_vector_inserts(pg_notice, embed_model, commit_history_id):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        sql = '''\n",
    "            INSERT INTO commit_history_vector (id, embedding) \n",
    "                SELECT \n",
    "                    id,\n",
    "                    openai_embed (\n",
    "                        %(model)s,\n",
    "                        -- create a single text string representation of the commit\n",
    "                        author || commit_time::text || commit_id || commit_title || commit_comments,\n",
    "                        -- pass api key\n",
    "                        %(key)s\n",
    "                    ) as embedding\n",
    "                FROM commit_history where id = %(id)s\n",
    "        '''\n",
    "        cur.execute(sql, {'model': embed_model, 'key': open_ai_key, 'id': commit_history_id})\n",
    "        pg_notice()\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('Error in ch_vector_inserts: {}'.format(e)) \n",
    "\n",
    "def main():    \n",
    "    ClassObjs = Openai()\n",
    "    params = ClassObjs.get_params()\n",
    "    notices = ClassObjs.get_notices\n",
    "    create_commit_hist_table(notices)\n",
    "    commit_hist_data = read_commit_hist(params['ch_cols'])\n",
    "    write_commit_hist(commit_hist_data, notices) \n",
    "    \n",
    "    # BEFORE EMBEDDING CHECK COST!!!! -- if coolio, then uncomment ch_vector_table :)\n",
    "    embedding_cost = ClassObjs.get_total_embeddings_cost(commit_hist_data, params['encoding'], params['token_cost'])\n",
    "    print('embed cost: {}'.format(np.round(embedding_cost, 4)))\n",
    "    \n",
    "    # seems faster to iterate over ids versus import all together\n",
    "    create_vector_table(notices)\n",
    "    ids = fetch_ch_ids()\n",
    "    insert_count = 0\n",
    "    for id in ids:\n",
    "        ch_vector_inserts(notices, params['model'], id)   \n",
    "        insert_count += 1 \n",
    "        if insert_count % 100 == 0:\n",
    "            print('vectors inserted: {}'.format(insert_count))\n",
    "    return commit_hist_data, ids\n",
    "\n",
    "ret = main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
